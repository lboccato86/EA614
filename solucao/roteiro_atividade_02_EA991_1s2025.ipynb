{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lboccato86/EA614/blob/master/solucao/roteiro_atividade_02_EA991_1s2025.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqA2_J8lhekx"
      },
      "source": [
        "# Atividade 02: Reconhecimento de Atividades Humanas com kNN, SVM e _Random Forest_\n",
        "\n",
        "<img src=\"https://github.com/EA991-Lab/utils/blob/main/figs/HAR_acc_gyr.png?raw=true\">\n",
        "\n",
        "*Dataset*: DAGHAR - https://zenodo.org/records/13987073\n",
        "\n",
        "Github: https://github.com/H-IAAC/DAGHAR\n",
        "\n",
        "O *benchmark* DAGHAR é uma coleção curada de conjuntos de dados projetada para estudos de adaptação de domínio e generalização de domínio em tarefas ligadas ao reconhecimento de atividades humanas (HAR, do inglês *human activity recognition*). As amostras disponíveis contêm dados brutos de sensores inerciais (acelerômetro e giroscópio) provenientes exclusivamente de *smartphones*.\n",
        "\n",
        "Nesta atividade, vamos trabalhar com a *baseline view* do DAGHAR, que preserva ao máximo as características dos *datasets* originais (como a taxa de amostragem).\n",
        "\n",
        "**Informações padronizadas:**\n",
        "\n",
        "- 6 classes\n",
        "\n",
        "| Rótulo    | Atividade |\n",
        "| :----:    |    :---   \n",
        "| 0   | Estar sentado       \n",
        "| 1   | Ficar em pé        \n",
        "| 2   | Caminhar        \n",
        "| 3   | Subir escadas      \n",
        "| 4   | Descer escadas\n",
        "| 5   | Correr      \n",
        "\n",
        "- Cada amostra contém janelas de 3 segundos (sem sobreposição) concatenadas de Acc-x, Acc-y, Acc-z, Gyr-x, Gyr-y, Gyr-z.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlZbxDOlkB6H"
      },
      "source": [
        "## Preâmbulo: Baixando o DAGHAR _baseline_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "64sQE-yT7esk"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import os\n",
        "from pathlib import Path\n",
        "from zipfile import ZipFile\n",
        "\n",
        "# Caminho para a pasta que conterá o dataset\n",
        "data_path = Path(\"data/\")\n",
        "\n",
        "def get_DARGHAR_data():\n",
        "    if not os.path.exists(data_path):\n",
        "        os.makedirs(\"data/\", exist_ok=True)\n",
        "\n",
        "        # Baixando o dataset do Zenodo\n",
        "        data_url = \"https://zenodo.org/records/13987073/files/baseline_view.zip?download=1\"\n",
        "        print(f\"Baixando dados de {data_url}...\")\n",
        "\n",
        "        #Baseline view\n",
        "        with open(\"baseline_view.zip\", \"wb\") as f:\n",
        "            request = requests.get(data_url)\n",
        "            f.write(request.content)\n",
        "\n",
        "        # Unzip\n",
        "        targ_dir = \"data\"\n",
        "        print(f\"Extraindo dados para {targ_dir}...\")\n",
        "        with ZipFile(\"baseline_view.zip\") as zip_ref:\n",
        "            zip_ref.extractall(targ_dir)\n",
        "    else:\n",
        "        print(\"Dataset já baixado!\")\n",
        "\n",
        "#Baixando o dataset DAGHAR completo\n",
        "get_DARGHAR_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parte 1: Conhecendo detalhes do problema e do *dataset*\n",
        "\n",
        "Escolha um conjunto de dados que compõe o DAGHAR e faça o carregamento das partições de treinamento, validação e teste.\n",
        "\n",
        "**Passos:**\n",
        "- definir o nome do subdiretório correspondente ao *dataset*;\n",
        "- ler os arquivos `train.csv`, `validation.csv` e `test.csv`."
      ],
      "metadata": {
        "id": "fUIc7S_QY7PE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hqlDqrmt-3IC"
      },
      "outputs": [],
      "source": [
        "#Caminho para a pasta que conterá o dataset\n",
        "folder = \"SUBSTITUIR PELO NOME DO DIRETÓRIO\"\n",
        "dataset_path = data_path / folder\n",
        "\n",
        "#Leitura das partições de treinamento, validação e teste\n",
        "data_train = pd.read_csv(dataset_path / \"train.csv\")\n",
        "data_val = pd.read_csv(dataset_path / \"validation.csv\")\n",
        "data_test = pd.read_csv(dataset_path / \"test.csv\")\n",
        "\n",
        "print(f\"Dimensão do dataset de treinamento: {data_train.shape}\")\n",
        "print(f\"Dimensão do dataset de validação: {data_val.shape}\")\n",
        "print(f\"Dimensão do dataset de teste: {data_test.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N8BiFuNJq36j"
      },
      "outputs": [],
      "source": [
        "#Lista com os nomes das classes na ordem correspondente aos rótulos numéricos\n",
        "class_names = ['Sitting','Standing','Walking','Upstairs','Downstairs','Running']\n",
        "\n",
        "#mapeamento dos rótulos padronizados para os nomes das classes no DAGHAR\n",
        "label_map = {0:'Sitting',1:'Standing',2:'Walking',3:'Upstairs',4:'Downstairs',5:'Running'}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "O `DataFrame` correspondente a cada *dataset* contém colunas adicionais com informações específicas (como índice de usuário) que não serão exploradas na atividade. Por isso, é necessário realizar uma limpeza inicial a fim de reter apenas as medidas de acelerômetro e giroscópio juntamente com o rótulo da atividade."
      ],
      "metadata": {
        "id": "Ow1b4kwSabpb"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AhFdB5IFkCS"
      },
      "source": [
        "a) Sorteie aleatoriamente uma amostra de cada classe e apresente as séries temporais correspondentes aos três eixos de acelerômetro e de giroscópio. Discuta brevemente o perfil das atividades com base nestas séries temporais.\n",
        "\n",
        "b) No problema de HAR, a representação no domínio da frequência para cada sinal (Acc-x, Acc-y, ..., Gyr-z) tende a favorecer a separação das classes, levando a um agrupamento das amostras de acordo com a \"energia\" da atividade. Por isso, vamos aplicar a transformada de Fourier a cada sinal básico (Acc-x, Acc-y, $\\ldots$, Gyr-z) e gerar um vetor de características formado pela concatenação da magnitude dos espectros:\n",
        "\n",
        "$$\\text{Vetor de atributos} = [\\, |\\text{DFT}(\\text{Acc-x})|\\;,\\;|\\text{DFT}(\\text{Acc-y})|\\;,\\;|\\text{DFT}(\\text{Acc-z})|\\;,\\; |\\text{DFT}(\\text{Gyr-x})|\\;,\\; |\\text{DFT}(\\text{Gyr-y})|\\;,\\; |\\text{DFT}(\\text{Gyr-z})|]$$\n",
        "\n",
        "Prepare, então, uma rotina que faça esta transformação das partições de treinamento, validação e teste. Em seguida, mostre a magnitude dos espectros das amostras selecionadas no item anterior (uma por atividade) e comente.\n",
        "\n",
        "c) Utilizando o algoritmo t-SNE (https://www.jmlr.org/papers/v9/vandermaaten08a.html), obtenha uma visualização em duas dimensões dos dados de treinamento e validação combinados.\n",
        "\n",
        "**Sugestão:** utilize o `plotly.express` para gerar uma figura interativa; cada amostra será um ponto no espaço bidimensional cuja cor deve indicar a atividade humana correspondente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8SsiBHzUzAZn"
      },
      "outputs": [],
      "source": [
        "from sklearn import manifold\n",
        "\n",
        "\"\"\" Vamos usar uma técnica chamada t-SNE para mapear os dados numa representação 2D de forma não-linear buscando preservar as relações\n",
        "    de vizinhança (probabilística) entre as amostras.\n",
        "\"\"\"\n",
        "t_sne = manifold.TSNE(\n",
        "    n_components=2,\n",
        "    perplexity=30,\n",
        "    #init=\"random\",\n",
        "    #random_state=0,\n",
        ")\n",
        "\n",
        "X_t_sne = \"\"\" APLICAR O TSNE À CONCATENAÇÃO DOS DADOS DE TREINAMENTO E VALIDAÇÃO \"\"\"\n",
        "\n",
        "#DataFrame com o resultado do t-SNE\n",
        "tsne_result = pd.DataFrame(X_t_sne,columns=['tsne1','tsne2'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F9EhQf6NzOlm"
      },
      "outputs": [],
      "source": [
        "import plotly.express as px\n",
        "\n",
        "fig = px.scatter(tsne_result, x='PREENCHER', y='PREENCHER', color=\"PREENCHER\",labels={'color': 'Atividade'})\n",
        "\n",
        "fig.update_layout(legend=dict(\n",
        "    orientation=\"h\",\n",
        "    entrywidth=70,\n",
        "    yanchor=\"bottom\",\n",
        "    y=1.02,\n",
        "    xanchor=\"right\",\n",
        "    x=0.8\n",
        "))\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parte 2: Aplicação de SVM"
      ],
      "metadata": {
        "id": "AQBzJG9SfD8u"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOUtAZBvJCaC"
      },
      "source": [
        "Ajuste de hiperparâmetros com busca em grade e validação cruzada (*holdout*) + aplicação ao conjunto de teste\n",
        "\n",
        "**Nota:** para usar um conjunto de validação pré-estabelecido junto ao `GridSearchCV`, é preciso:\n",
        "1. Concatenar as partições de treinamento e validação;\n",
        "2. Criar uma lista de índices 0 e -1 de mesmo tamanho que o total de amostras de treinamento + validação: os 0s aparecem para as amostras de validação, e -1s para as amostras de treinamento;\n",
        "3. Usar `PredefinedSplit` com a lista de índices para preparar um separador de dados de validação;\n",
        "4. Passar o *splitter* através do parâmetro `cv` do `GridSearchCV`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lE2ilfRMJGkA"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV, PredefinedSplit\n",
        "from sklearn.metrics import classification_report, confusion_matrix, f1_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPIsWNCtxANm"
      },
      "source": [
        "d) Apresente uma curva de variação de uma métrica de desempenho (e.g., $F_1$-*score*) nos dados de validação em função da largura da função *kernel* considerando a opção de *kernel* Gaussiano (ou `rbf`). Comente.\n",
        "\n",
        "e) Descreva sucintamente a metodologia empregada e apresente os resultados obtidos no conjunto de teste pela melhor configuração do modelo, incluindo: acurácia, $F_1$-*score* e matriz de confusão.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "gQlp4uaSAcqq"
      },
      "outputs": [],
      "source": [
        "\"\"\" COMPLETAR A CÉLULA \"\"\"\n",
        "\n",
        "# Define o grid de parâmetros\n",
        "param_grid = {\n",
        "\n",
        "    #'C': [],\n",
        "    #'gamma': np.logspace(),\n",
        "    #'kernel': []\n",
        "}\n",
        "\n",
        "\n",
        "#lista de índices para a separação novamente em X_train e X_val dentro do GridSearch\n",
        "split_index = [-1]*len(X_train) + [0]*len(X_val)\n",
        "\n",
        "#cria o splitter de dados\n",
        "pds = PredefinedSplit(test_fold = split_index)\n",
        "\n",
        "#define a busca em grade\n",
        "grid = GridSearchCV()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ayI8k3zHgmw"
      },
      "source": [
        "## Parte 3: Aplicação de kNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ob0WrE9xiVRp"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6P0FCeFHj7F"
      },
      "source": [
        "f) Mostre em um gráfico a variação da mesma métrica de desempenho no conjunto de validação em função do número de vizinhos ($k$). Comente.\n",
        "\n",
        "g) Descreva sucintamente a metodologia empregada e apresente os resultados obtidos no conjunto de teste pela melhor configuração do modelo, incluindo: acurácia, $F_1$-*score* e matriz de confusão."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbVHW5OwHsvj"
      },
      "source": [
        "## Parte 4: Aplicação de *Random Forest*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "MR_Gw16CqGG-"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUh2wkmkp1-w"
      },
      "source": [
        "h) Mostre o impacto do número de árvores (`n_estimators`) sobre o desempenho de validação considerando como função de impureza (`criterion`) o índice de Gini e a entropia. Comente.\n",
        "\n",
        "i) Descreva sucintamente a metodologia empregada e apresente os resultados obtidos no conjunto de teste pela melhor configuração do modelo, incluindo: acurácia, $F_1$-*score* e matriz de confusão."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yzTByFvHxUu"
      },
      "source": [
        "## Parte 5: Extensão para outros dois *datasets*\n",
        "\n",
        "j) Repita o procedimento adotado nas Partes 1 a 4 para outros dois *datasets* de sua escolha contidos no DAGHAR. Ao final de todos os passos, mostre numa tabela os desempenhos de teste alcançados pelos modelos nos três *datasets*.\n",
        "\n",
        "| Modelo    | *Dataset* 1 | *Dataset* 2 | *Dataset* 3 |  Média e Desvio Padrão\n",
        "| :----:    |    :---   |    :---   |    :---   | :---   \n",
        "| SVM   |        \n",
        "| kNN |        \n",
        "| *Random Forest* |\n",
        "\n",
        "k) Aplique, ao final, um teste estatístico não-paramétrico (e.g., Wilcoxon) em todos os pares de modelos - SVM vs. kNN, SVM vs. *Random Forest* e kNN vs. *Random Forest* e obtenha os p-valores. Verifique se há diferença que possa ser considerada significativa entre eles.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}